

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Envoutante">
  <meta name="keywords" content="">
  
    <meta name="description" content="Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting 参考博客 知乎：Attention 跟一维卷积的区别是啥？ 核心思想 RNN 结合 Attention 里有 Attention 结合 CNN   Abstract GA-RNN 模型主要是为了处理多个实体随时间相互">
<meta property="og:type" content="article">
<meta property="og:title" content="Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting">
<meta property="og:url" content="http://example.com/2023/12/01/GA-RNN/index.html">
<meta property="og:site_name" content="Envoutante&#39;s Blog">
<meta property="og:description" content="Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting 参考博客 知乎：Attention 跟一维卷积的区别是啥？ 核心思想 RNN 结合 Attention 里有 Attention 结合 CNN   Abstract GA-RNN 模型主要是为了处理多个实体随时间相互">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-12-01T09:03:28.929Z">
<meta property="article:modified_time" content="2023-12-02T08:22:38.762Z">
<meta property="article:author" content="Envoutante">
<meta property="article:tag" content="RNN">
<meta property="article:tag" content="Attention">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting - Envoutante&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Envoutante&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-12-01 17:03" pubdate>
          2023年12月1日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.3k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          28 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting</h1>
            
            
              <div class="markdown-body">
                
                <h1
id="graph-attention-recurrent-neural-networks-for-correlated-time-series-forecasting">Graph
Attention Recurrent Neural Networks for Correlated Time Series
Forecasting</h1>
<p><strong>参考博客</strong></p>
<p>知乎：<a
target="_blank" rel="noopener" href="https://www.zhihu.com/question/288081659/answer/1222002868">Attention
跟一维卷积的区别是啥？</a></p>
<p><strong>核心思想</strong></p>
<p>RNN 结合 Attention 里有 Attention 结合 CNN</p>
<p> </p>
<h2 id="abstract">Abstract</h2>
<p><strong>GA-RNN
模型</strong>主要是为了处理<strong>多个实体随时间相互作用</strong>的情况，其中实体随时间变化的状态（time-varying
status）可以被表示为一个时间序列（time
series），而且这些时间序列是相互关联（correlated）的。</p>
<p><strong>核心场景：</strong>在公路的不同位置上都部署有速度传感器，这些传感器全天捕捉的车速将形成一个时间序列，并且各个时间序列之间通常是有联系的。</p>
<blockquote>
<p>训练集：速度时间序列数据集。</p>
</blockquote>
<p>下图是一个例子。在早上 7:00 的时候，实体 D 和 B、C
的相关性很强，而在早上 9:00 的时候，实体 D 和 E、F
的相关性很强。所以实体之间的相关性是随时间动态变化的。</p>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN1.png" srcset="/img/loading.gif" lazyload
alt="动态相互作用" />
<figcaption aria-hidden="true">动态相互作用</figcaption>
</figure>
<p><strong>本文的 IDEA：</strong></p>
<ol type="1">
<li>空间方面：时间序列之间是相互关联的，因此采用 attention
进行捕捉。</li>
<li>时间方面：时间序列内部存在时间依赖性，因此采用 GRU 进行捕捉。</li>
</ol>
<blockquote>
<p>先 1 后 2，且 2 结合 1，从而能够捕捉时空关系（spatio-temporal
correlations）</p>
</blockquote>
<p> </p>
<h2 id="introduction">Introduction</h2>
<p><strong>GA-RNN 简述：</strong></p>
<ol type="1">
<li>作者根据空间邻近性（spatial
proximity）来搭建了一个图。在本文中，实体 entity/entities 被称为
vertex/vertices，用邻接矩阵来表示两个实体之间是否有 edge 边。</li>
<li>为每个实体计算 attention
score，以考察该实体和它的哪个邻居（1-hop）的相关性更高，事实上该值还被用作了邻接矩阵中的值。</li>
<li>使用 RNN 来捕捉时空依赖关系（spatio-temporal
dependency），作者还将经典 RNN 单元中的权重乘法（weight
multiplications）替换为考虑图拓扑的卷积（convolutions），比如图卷积或扩散卷积。</li>
</ol>
<p><strong>主要贡献：</strong>利用注意力机制来生成动态变化的邻接矩阵，再将其用于
RNN 来捕获时空依赖关系。</p>
<blockquote>
<p>这就忽略了语义关系吧？图卷积和扩散卷积是能产生邻接矩阵吗？</p>
</blockquote>
<p> </p>
<h2 id="problem-definition">PROBLEM DEFINITION</h2>
<p>为了更好地帮助读者理解，作者还详细地说明了如何将现实问题转换为符号来表达。</p>
<h3 id="time-series">Time Series</h3>
<p>假设有 <span class="math inline">\(N\)</span> 个实体，<span
class="math inline">\(T\)</span>
个时间戳，那么每个实体在某一时间戳的状态被表示为 <span
class="math inline">\(x_t\)</span> 。对于第 <span
class="math inline">\(i\)</span> 个实体，则它的所有状态构成一个时间序列
<span
class="math inline">\(TS^{(i)}=&lt;x_{1}^{(i)},...,x_{T}^{(i)}&gt;\)</span>，其中
<span class="math inline">\(x_t\)</span> 是一个 <span
class="math inline">\(K\)</span>
维的特征向量。至此，我们将能够表示所有的时间序列：<span
class="math inline">\(TS^{(1)},...,TS^{(N)}\)</span> 。</p>
<p><strong>任务要求：</strong>给定所有实体的历史状态，预测所有实体的未来状态。历史状态和未来状态都用滑动窗口
window 来表示：</p>
<ul>
<li>历史状态是指前 <span class="math inline">\(L\)</span> 个时间戳，即
<span class="math inline">\([t_{a-L+1},t_{a}]\)</span> 窗口</li>
<li>未来状态是指后 <span class="math inline">\(P\)</span> 个时间戳，即
<span class="math inline">\([t_{a+1},t_{a+P}]\)</span> 窗口</li>
</ul>
<p>因此又被称为 p-step ahead forecasting 问题。</p>
<p> </p>
<h3 id="graph-signals">Graph Signals</h3>
<p>建立有向图 <span class="math inline">\(G=(V,E)\)</span>，其中 <span
class="math inline">\(v \in V\)</span> 表示每个实体，且有 <span
class="math inline">\(|V|=N\)</span> 。用邻接矩阵 <span
class="math inline">\(E \in R^{N \times N}\)</span>
来表示所有的边，如果实体 <span class="math inline">\(i\)</span> 和实体
<span class="math inline">\(j\)</span> 之间有边则 <span
class="math inline">\(E[i,j]=1\)</span> 。</p>
<blockquote>
<p>显然，这个边不包含任何的语义信息，需要调整后才能用到知识图谱中。</p>
</blockquote>
<p>对于某一时刻 <span
class="math inline">\(t\)</span>，所有实体向量的集合为 <span
class="math inline">\(X_{t} \in R^{N \times
K}=[x_{t}^{(1)},...,x_{t}^{(N)}]^{T}\)</span>，其中 <span
class="math inline">\(x_t\)</span> 是一个 <span
class="math inline">\(K\)</span>
维的特征向量。下标表示是哪一个时刻，上标表示是哪一个实体。</p>
<p>从而有：</p>
<ul>
<li>历史状态输入为 <span class="math inline">\(X^{(L)}
=[X_{t-L+1},...,X_{t}]\)</span></li>
<li>未来状态输入为 <span class="math inline">\(X^{(P)}
=[X_{t+1},...,X_{t+P}]\)</span></li>
</ul>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN2.png" srcset="/img/loading.gif" lazyload
alt="(a)为X_{t}   (b)为X^{(L)}   其中维度K=3" />
<figcaption aria-hidden="true">(a)为<span
class="math inline">\(X_{t}\)</span>   (b)为<span
class="math inline">\(X^{(L)}\)</span>   其中维度<span
class="math inline">\(K=3\)</span></figcaption>
</figure>
<p> </p>
<h2 id="ga-rnn">GA-RNN</h2>
<p>Graph Attention RNN：分为 attention 部分和 RNN 部分，并且使用的是
encoder-decoder 架构。</p>
<h3 id="spatial-modeling">Spatial Modeling</h3>
<p>为在集合 <span class="math inline">\(NB(i)=\left \{j|E[i,j]=1\right
\}\cup\left \{i\right \}\)</span> 中的实体计算 attention score，即实体
<span class="math inline">\(i\)</span> 的（1-hop）邻居和 <span
class="math inline">\(i\)</span> 自己。</p>
<p>以下是计算流程：假设实体 <span class="math inline">\(i\)</span> 在
<span class="math inline">\(t\)</span> 时刻的状态为 <span
class="math inline">\(x_{t}^{(i)}\in R^{K}\)</span>，实体 <span
class="math inline">\(j\)</span> 是集合 <span
class="math inline">\(NB(i)\)</span>中的一个元素。</p>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN3.png" srcset="/img/loading.gif" lazyload
alt="attention score" />
<figcaption aria-hidden="true">attention score</figcaption>
</figure>
<p><span class="math inline">\(A_{t}\)</span> 是 <span
class="math inline">\(t\)</span> 时刻的邻接矩阵，<span
class="math inline">\(A_{t}[i,j]\)</span> 是实体 <span
class="math inline">\(i\)</span> 和 <span
class="math inline">\(j\)</span> 之间的边，可见 edge
被定义为实体之间的相关度。这里采用的计算相似度的方法应该是
Additive，和之前看的 GGAM 模型是一样的。</p>
<blockquote>
<p>区别在于 GGAM 还考虑了关系 r，而 GA-RNN 和 GAT
都只考虑了两个实体之间的相似度。</p>
</blockquote>
<p>维度说明：</p>
<ul>
<li><span class="math inline">\(x_{t}^{(i)}\in R^{K}\)</span></li>
<li><span class="math inline">\(W\in R^{F\times K}\)</span></li>
<li><span class="math inline">\(v\in R^{2F\times 1}\)</span></li>
</ul>
<p><strong>multi-head attention</strong></p>
<blockquote>
<p>Motivated by [17], we observe that stacking multiple attention
networks, a.k.a., attention heads, is beneficial since each attention
network can specialise on capturing different interactions.</p>
<p>多头注意力机制可以用来捕获不同的关系。</p>
</blockquote>
<p>同样作者也用了多头注意力机制，并且最后用的是 averaging：</p>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN4.png" srcset="/img/loading.gif" lazyload
alt="multi-head attention score" />
<figcaption aria-hidden="true">multi-head attention score</figcaption>
</figure>
<p>维度说明：</p>
<ul>
<li><span class="math inline">\(x_{t}^{(i)}\in R^{K}\)</span></li>
<li><span class="math inline">\(W^{(c)}\in R^{F\times K}\)</span></li>
<li><span class="math inline">\(v^{(c)}\in R^{2F\times 1}\)</span></li>
</ul>
<p>GA-RNN 等并没有像 Transformer
一样把一个单头劈成多个头，而是保持和单头时的维度一致。</p>
<p>根据上述操作，我们可以分别计算出 <span
class="math inline">\(t\)</span> 时刻的两个邻接矩阵 <span
class="math inline">\(A_{t}^{(in)}\)</span> 和 <span
class="math inline">\(A_{t}^{(out)}\)</span>，分别对应流入的流量和流出的流量。此外，虽然
<span class="math inline">\(W^{(c)}\)</span> 和 <span
class="math inline">\(v^{(c)}\)</span> 是固定的，但是由于 <span
class="math inline">\(x_{t}\)</span>
随时间的变化而变化，因此邻接矩阵也是动态变化的。</p>
<p> </p>
<h3 id="spatio-temporal-modeling">Spatio-Temporal Modeling</h3>
<p>定义一个扩散卷积操作：</p>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN5.png" srcset="/img/loading.gif" lazyload
alt="convolution operation" />
<figcaption aria-hidden="true">convolution operation</figcaption>
</figure>
<p>暂时只涉及下图中的三个变量：</p>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN6.png" srcset="/img/loading.gif" lazyload
alt="RNN unit" />
<figcaption aria-hidden="true">RNN unit</figcaption>
</figure>
<blockquote>
<p>目前的理解：<span class="math inline">\(\Theta\)</span>
是一个卷积核，又称 filter 过滤器。本文的 <span
class="math inline">\(\Theta\)</span> 是一个张量，有 2 个通道，<span
class="math inline">\(\theta_{k,h,1}\)</span> 和 <span
class="math inline">\(\theta_{k,h,2}\)</span> 是 <span
class="math inline">\(\Theta\)</span> 对应位置上的权重。而 attention
计算出来的 <span class="math inline">\(A_{t}^{out}\)</span> 和 <span
class="math inline">\(A_{t}^{in}\)</span>
对卷积核的权重起到动态调整的作用，因此被称为动态卷积。</p>
</blockquote>
<p>本文使用的是 RNN 的变形体
GRU，并且还用上面定义的扩散卷积操作替换了原本的线性变换操作：</p>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN8.png" srcset="/img/loading.gif" lazyload
alt="GRU unit" />
<figcaption aria-hidden="true">GRU unit</figcaption>
</figure>
<p> </p>
<h3 id="loss-function">Loss Function</h3>
<p>损失函数如下：</p>
<figure>
<img
src="https://hexo-0711.oss-cn-chengdu.aliyuncs.com/image/GARNN7.png" srcset="/img/loading.gif" lazyload
alt="loss function" />
<figcaption aria-hidden="true">loss function</figcaption>
</figure>
<p>参数说明：</p>
<ul>
<li><span class="math inline">\(Y\)</span> 代表有 <span
class="math inline">\(Y\)</span> 个样本实例（training instances）</li>
<li><span class="math inline">\(N\)</span> 代表有 <span
class="math inline">\(N\)</span> 个实体</li>
<li><span class="math inline">\(P\)</span> 代表预测的 <span
class="math inline">\(P\)</span> 个未来状态</li>
<li><span class="math inline">\(x_{p,y}\)</span> 代表真实值 GT</li>
<li><span class="math inline">\(\widehat{x}_{p,y}\)</span> 代表 GA-RNN
的预测值</li>
</ul>
<blockquote>
<p>每个训练实例都是一个包含输入数据和对应标签的样本，按个人理解就是包含了一组样本点。</p>
</blockquote>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RNN/" class="print-no-link">#RNN</a>
      
        <a href="/tags/Attention/" class="print-no-link">#Attention</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting</div>
      <div>http://example.com/2023/12/01/GA-RNN/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Envoutante</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年12月1日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/12/01/RNN&amp;CNN/" title="RNN 和 CNN 基础">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">RNN 和 CNN 基础</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/12/01/RNN&amp;CNN&amp;Attention/" title="RNN、CNN、Attention 三者比较">
                        <span class="hidden-mobile">RNN、CNN、Attention 三者比较</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
